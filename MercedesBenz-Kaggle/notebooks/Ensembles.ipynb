{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\ml_env\\lib\\site-packages\\IPython\\html.py:14: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"D:/ML_Projects/MercedesBenz-Kaggle/\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, ShuffleSplit, KFold, train_test_split\n",
    "import sklearn.metrics as mt\n",
    "from sklearn import svm, ensemble\n",
    "from sklearn.linear_model import LinearRegression, BayesianRidge, ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0,
     6,
     56
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    train_data = pd.read_csv(\"./data/train.csv\")\n",
    "    test_data = pd.read_csv(\"./data/test.csv\")\n",
    "    return train_data, test_data\n",
    "\n",
    "\n",
    "def process_data(train_data, test_data):\n",
    "    binary_cols, all_zero_cols, all_one_cols = [],[],[]\n",
    "    for col in train_data.iloc[:,10:]:\n",
    "        unique_vals = train_data[col].unique()\n",
    "        if np.array_equal(unique_vals, [1,0]) or np.array_equal(unique_vals, [0,1]):\n",
    "            binary_cols.append(col)\n",
    "        elif np.array_equal(unique_vals, [0]):\n",
    "            all_zero_cols.append(col)\n",
    "        elif np.array_equal(unique_vals, [1]):\n",
    "            all_one_cols.append(col)\n",
    "        else:\n",
    "            print(unique_vals)\n",
    "\n",
    "    # Drop columns with only zeros\n",
    "    train_data = train_data.drop(all_zero_cols, axis=1)\n",
    "    test_data = test_data.drop(all_zero_cols, axis=1)\n",
    "    \n",
    "    train_cat_cols = train_data.iloc[:,2:10]\n",
    "    test_cat_cols = test_data.iloc[:,1:9]\n",
    "    freq=[]\n",
    "    col_names = []\n",
    "    cat_mismatch = []\n",
    "    \n",
    "    for train_col, test_col in zip(train_cat_cols, test_cat_cols):\n",
    "        col_names.append(train_col)\n",
    "        train_freq = len(train_cat_cols[train_col].unique())\n",
    "        test_freq = len(test_cat_cols[test_col].unique())\n",
    "        \n",
    "        if train_freq!=test_freq:\n",
    "            cat_mismatch.append(train_col)\n",
    "            \n",
    "        freq.append([train_freq, test_freq])\n",
    "    freq = pd.DataFrame(freq, columns=['Train_Freq', 'Test_Freq'], index=col_names)\n",
    "    \n",
    "    train_data = train_data.drop(cat_mismatch, axis=1)\n",
    "    test_data = test_data.drop(cat_mismatch, axis=1)\n",
    "    return train_data, test_data\n",
    "\n",
    "\n",
    "def prepare_data_ml(train_data, test_data):\n",
    "    X_train = pd.get_dummies(train_data)\n",
    "    X_train = X_train.drop(['ID','y'], axis=1).values\n",
    "    y_train = train_data.y.values\n",
    "    \n",
    "    X_test = pd.get_dummies(test_data)\n",
    "    y_test_id = test_data.ID.values\n",
    "    X_test = X_test.drop(['ID'], axis=1).values\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test_id\n",
    "\n",
    "def make_submission(reg_estimator, X_test, ID, fname='FinalSubmission'):\n",
    "    y_pred = reg_estimator.predict(X_test)\n",
    "    final_submission = pd.DataFrame(np.hstack([ID[:,np.newaxis], y_pred[:,np.newaxis]]), columns=['ID','y'])\n",
    "    final_submission.ID = final_submission.ID.astype(int)\n",
    "    final_submission.to_csv('./results/'+fname, index=False)\n",
    "    return final_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_regressor(regressor_obj, X_train, y_train):\n",
    "    print(regressor_obj)\n",
    "    regressor_obj.fit(X_train, y_train)\n",
    "    y_train_pred = regressor_obj.predict(X_train)\n",
    "    \n",
    "    r_2 = mt.r2_score(y_train, y_train_pred) # Coefficient of determination\n",
    "    mse = mt.mean_squared_error(y_train, y_train_pred) # Mean squared error\n",
    "    \n",
    "    print(\"Coefficient of Determination: \", r_2)\n",
    "    print(\"Mean Square Error: \", mse)\n",
    "    \n",
    "    return regressor_obj, y_train_pred\n",
    "\n",
    "def perf_regressor(regressor_obj, x, y):\n",
    "    print(regressor_obj)\n",
    "    pred = regressor_obj.predict(x)\n",
    "    \n",
    "    r_2 = mt.r2_score(y, pred) # Coefficient of determination\n",
    "    mse = mt.mean_squared_error(y, pred) # Mean squared error\n",
    "    \n",
    "    print(\"Test Performance\")\n",
    "    print(\"Coefficient of Determination: \", r_2)\n",
    "    print(\"Mean Square Error: \", mse)\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Samples:  (4209, 431)\n",
      "Test Sample:  (4209, 431)\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = read_data()\n",
    "train_data, test_data = process_data(train_data, test_data)\n",
    "\n",
    "X, y, X_test, y_test_id = prepare_data_ml(train_data, test_data)\n",
    "\n",
    "print(\"Training Samples: \", X.shape)\n",
    "print(\"Test Sample: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stack GBM's - add white noise to output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++ Fold 0 +++++++++++++++\n",
      "==============Regression Model 1==============\n",
      "R2 : -3.51\n",
      "==============Regression Model 2==============\n",
      "R2 : -3.58\n",
      "==============Regression Model 3==============\n",
      "R2 : 0.58\n",
      "++++++++++++++ Fold 1 +++++++++++++++\n",
      "==============Regression Model 1==============\n",
      "R2 : -3.30\n",
      "==============Regression Model 2==============\n",
      "R2 : -3.30\n",
      "==============Regression Model 3==============\n",
      "R2 : 0.53\n"
     ]
    }
   ],
   "source": [
    "cv_kfold = KFold(n_splits=2, shuffle=True)\n",
    "i = 0\n",
    "for train_idx, val_idx in cv_kfold.split(X, y):\n",
    "    print(\"++++++++++++++ Fold %d +++++++++++++++\" %(i))\n",
    "    x_train, x_val = X[train_idx], X[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "    \n",
    "    print (\"==============Regression Model 1==============\")\n",
    "    \n",
    "    regressor1 = ensemble.GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse',\n",
    "                                                   learning_rate=0.01, loss='ls', max_depth=3,\n",
    "                                                   max_features='sqrt',\n",
    "                                                   min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "                                                   n_estimators=1000, random_state=122,\n",
    "                                                   subsample=1, verbose=0)\n",
    "    regressor1.fit(x_train, y_train*1.25)\n",
    "    pred1 = regressor1.predict(x_val).reshape(x_val.shape[0],1)\n",
    "    print(\"R2 : %0.2f\" %(mt.r2_score(y_val, pred1)))\n",
    "    \n",
    "    print (\"==============Regression Model 2==============\")\n",
    "    \n",
    "    regressor2 = ensemble.GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse',\n",
    "                                                   learning_rate=0.01, loss='ls', max_depth=3,\n",
    "                                                   max_features='sqrt',\n",
    "                                                   min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "                                                   n_estimators=1000, random_state=122,\n",
    "                                                   subsample=1, verbose=0)\n",
    "    regressor2.fit(x_train, y_train*0.75)\n",
    "    pred2 = regressor2.predict(x_val).reshape(x_val.shape[0],1)\n",
    "    print(\"R2 : %0.2f\" %(mt.r2_score(y_val, pred2)))\n",
    "    \n",
    "    print (\"==============Regression Model 3==============\")\n",
    "    \n",
    "    regressor3 = ensemble.GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse',\n",
    "                                                   learning_rate=0.01, loss='ls', max_depth=3,\n",
    "                                                   max_features='sqrt',\n",
    "                                                   min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "                                                   n_estimators=1000, random_state=122,\n",
    "                                                   subsample=1, verbose=0)\n",
    "    regressor3.fit(x_train, y_train)\n",
    "    pred3 = regressor3.predict(x_val).reshape(x_val.shape[0],1)\n",
    "    print(\"R2 : %0.2f\" %(mt.r2_score(y_val, pred3)))\n",
    "    \n",
    "    if i==0:\n",
    "        x_train_meta = np.empty(shape=(x_val.shape[0], x_val.shape[1]))\n",
    "        x_train_meta = np.hstack((x_val, pred1, pred2, pred3))\n",
    "    else:\n",
    "        x_train_fold = np.hstack((x_val, pred1, pred2, pred3))\n",
    "        x_train_meta = np.vstack((x_train_meta, x_train_fold))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor1 = ensemble.GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse',\n",
    "                                                   learning_rate=0.01, loss='ls', max_depth=3,\n",
    "                                                   max_features='sqrt',\n",
    "                                                   min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "                                                   n_estimators=1000, random_state=122,\n",
    "                                                   subsample=1, verbose=0)\n",
    "regressor1.fit(X, y*1.25)\n",
    "test_pred1 = regressor1.predict(X_test).reshape(X_test.shape[0],1)\n",
    "\n",
    "regressor2 = ensemble.GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse',\n",
    "                                                   learning_rate=0.01, loss='ls', max_depth=3,\n",
    "                                                   max_features='sqrt',\n",
    "                                                   min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "                                                   n_estimators=1000, random_state=122,\n",
    "                                                   subsample=1, verbose=0)\n",
    "regressor2.fit(X, y*0.75)\n",
    "test_pred2 = regressor2.predict(X_test).reshape(X_test.shape[0],1)\n",
    "\n",
    "regressor3 = ensemble.GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse',\n",
    "                                                   learning_rate=0.01, loss='ls', max_depth=3,\n",
    "                                                   max_features='sqrt',\n",
    "                                                   min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "                                                   n_estimators=1000, random_state=122,\n",
    "                                                   subsample=1, verbose=0)\n",
    "regressor3.fit(X, y)\n",
    "test_pred3 = regressor3.predict(X_test).reshape(X_test.shape[0],1)\n",
    "\n",
    "x_test_meta = np.hstack((X_test, test_pred1, test_pred2, test_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge(alpha=0.0001, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=True, random_state=None, solver='auto', tol=0.001)\n",
      "Coefficient of Determination:  0.116325325958\n",
      "Mean Square Error:  142.031716991\n"
     ]
    }
   ],
   "source": [
    "stacked_ridge = Ridge(alpha=0.0001, fit_intercept=True, normalize=True)\n",
    "stacked_ridge, stacked_pred = build_regressor(stacked_ridge, x_test_meta, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "62px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
